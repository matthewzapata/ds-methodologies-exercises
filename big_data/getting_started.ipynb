{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a SparkSession that connects to Spark in local mode. Configure the SparkSession to use two cores.\n",
    "1. Using the example from the lesson, create a spark data frame that contains your favorite programming languages. The name of the column should be language.\n",
    "1. Print the schema of the dataframe\n",
    "1. View the dataframe\n",
    "1. Count the number of records using .count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.master('local').\\\n",
    "config('spark.jars.packages', 'mysql:mysql-connector-java:8.0.16').\\\n",
    "config('spark.driver.memory', '4G').config('spark.driver.cores', 2).\\\n",
    "config('spark.sql.shuffle.partitions', 2).appName('MySparkApplication').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.createDataFrame([('Python', ), ('Swift', )], schema=['language'])\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pandas_dataframe = pd.DataFrame(dict(n=np.arange(100), group=np.random.choice(list('abc'), 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pandas_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  n|group|\n",
      "+---+-----+\n",
      "|  0|    a|\n",
      "|  1|    c|\n",
      "|  2|    c|\n",
      "|  3|    c|\n",
      "|  4|    b|\n",
      "+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grouping then aggregating average with expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|group|           avg(n)|\n",
      "+-----+-----------------+\n",
      "|    a|45.34285714285714|\n",
      "|    c|49.94871794871795|\n",
      "|    b|54.42307692307692|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, avg\n",
    "\n",
    "df.groupBy('group').agg(expr('avg(n)')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grouping then aggregating average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|group|           avg(n)|\n",
      "+-----+-----------------+\n",
      "|    a|45.34285714285714|\n",
      "|    c|49.94871794871795|\n",
      "|    b|54.42307692307692|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('group').agg(avg(df.n)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Similar to running a SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|letter|number_of_occurences|\n",
      "+------+--------------------+\n",
      "|     a|                  35|\n",
      "|     c|                  39|\n",
      "|     b|                  26|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT group as letter, count(n) as number_of_occurences\n",
    "FROM numbers\n",
    "GROUP BY group\n",
    "''').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SELECT statement like in MySQL and using expr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.select('n', 'group', expr('n + 1 as incremented'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------+\n",
      "|  n|group|incremented|\n",
      "+---+-----+-----------+\n",
      "|  0|    a|          1|\n",
      "|  1|    c|          2|\n",
      "|  2|    c|          3|\n",
      "|  3|    c|          4|\n",
      "|  4|    b|          5|\n",
      "+---+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting more similar to pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------+\n",
      "|  n|group|incremented|\n",
      "+---+-----+-----------+\n",
      "|  0|    a|          1|\n",
      "|  1|    c|          2|\n",
      "|  2|    c|          3|\n",
      "|  3|    c|          4|\n",
      "|  4|    b|          5|\n",
      "+---+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n, df.group, (df.n + 1).alias('incremented')).show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
